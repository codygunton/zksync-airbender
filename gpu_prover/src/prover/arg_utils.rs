use cs::definitions::{
    IndirectAccessColumns, LookupExpression, OptimizedOraclesForLookupWidth1,
    RegisterAccessColumns, RegisterAndIndirectAccessDescription, ShuffleRamAuxComparisonSet,
    ShuffleRamInitAndTeardownLayout,
    EXECUTOR_FAMILY_CIRCUIT_DECODER_TABLE_LINEARIZATION_CHALLENGES,
    MEM_ARGUMENT_CHALLENGE_POWERS_ADDRESS_HIGH_IDX, MEM_ARGUMENT_CHALLENGE_POWERS_ADDRESS_LOW_IDX,
    MEM_ARGUMENT_CHALLENGE_POWERS_TIMESTAMP_HIGH_IDX,
    MEM_ARGUMENT_CHALLENGE_POWERS_TIMESTAMP_LOW_IDX, MEM_ARGUMENT_CHALLENGE_POWERS_VALUE_HIGH_IDX,
    MEM_ARGUMENT_CHALLENGE_POWERS_VALUE_LOW_IDX, NUM_DELEGATION_ARGUMENT_KEY_PARTS,
    NUM_LOOKUP_ARGUMENT_KEY_PARTS, NUM_MACHINE_STATE_LINEARIZATION_CHALLENGES,
    NUM_MEM_ARGUMENT_KEY_PARTS, NUM_TIMESTAMP_COLUMNS_FOR_RAM, REGISTER_SIZE,
};
use cs::one_row_compiler::{
    ColumnAddress, CompiledCircuitArtifact, LookupWidth1SourceDestInformation,
    LookupWidth1SourceDestInformationForExpressions, RegisterOnlyAccessAddress,
    RegisterOrRamAccessAddress, ShuffleRamAddress, ShuffleRamQueryColumns,
};
use field::{Field, FieldExtension, PrimeField};
use prover::definitions::{
    ExternalDelegationArgumentChallenges, ExternalMachineStateArgumentChallenges,
    ExternalMemoryArgumentChallenges,
};
use prover::prover_stages::cached_data::ProverCachedData;

use super::{BF, E4};
use std::mem::size_of;
// TODO: Once we have an overall prove function, consider making a big standalone helper
// that creates all args common to stages 2 and 3.

// explicit repackaging struct ensures layout matches what cuda expects
#[derive(Clone, Default)]
#[repr(C)]
pub struct DelegationChallenges {
    pub linearization_challenges: [E4; NUM_DELEGATION_ARGUMENT_KEY_PARTS - 1],
    pub gamma: E4,
}

impl DelegationChallenges {
    pub fn new(challenges: &ExternalDelegationArgumentChallenges) -> Self {
        // ensures size matches corresponding cuda struct
        assert_eq!(NUM_DELEGATION_ARGUMENT_KEY_PARTS, 4);
        assert_eq!(
            challenges
                .delegation_argument_linearization_challenges
                .len(),
            NUM_DELEGATION_ARGUMENT_KEY_PARTS - 1
        );
        let linearization_challenges: [E4; NUM_DELEGATION_ARGUMENT_KEY_PARTS - 1] =
            std::array::from_fn(|i| challenges.delegation_argument_linearization_challenges[i]);
        Self {
            linearization_challenges,
            gamma: challenges.delegation_argument_gamma,
        }
    }
}

// explicit repackaging struct ensures layout matches what cuda expects
#[derive(Clone, Default)]
#[repr(C)]
pub struct MachineStateChallenges {
    pub linearization_challenges: [E4; NUM_MACHINE_STATE_LINEARIZATION_CHALLENGES],
    pub additive_term: E4,
}

impl MachineStateChallenges {
    pub fn new(challenges: &ExternalMachineStateArgumentChallenges) -> Self {
        // ensures size matches corresponding cuda struct
        assert_eq!(NUM_MACHINE_STATE_LINEARIZATION_CHALLENGES, 3);
        assert_eq!(
            challenges.linearization_challenges.len(),
            NUM_MACHINE_STATE_LINEARIZATION_CHALLENGES
        );
        let linearization_challenges: [E4; NUM_MACHINE_STATE_LINEARIZATION_CHALLENGES] =
            std::array::from_fn(|i| challenges.linearization_challenges[i]);
        Self {
            linearization_challenges,
            additive_term: challenges.additive_term,
        }
    }
}

#[derive(Clone, Default)]
#[repr(C)]
pub struct DelegationRequestMetadata {
    pub multiplicity_col: u32,
    pub timestamp_col: u32,
    pub memory_timestamp_high_from_circuit_idx: BF,
    pub delegation_type_col: u32,
    pub in_cycle_write_idx: BF,
    pub abi_mem_offset_high_col: u32,
    pub has_abi_mem_offset_high: bool,
}

#[derive(Clone, Default)]
#[repr(C)]
pub struct DelegationProcessingMetadata {
    pub multiplicity_col: u32,
    pub delegation_type: BF,
    pub write_timestamp_col: u32,
    pub abi_mem_offset_high_col: u32,
    pub has_abi_mem_offset_high: bool,
}

pub fn get_delegation_metadata(
    cached_data: &ProverCachedData,
    circuit: &CompiledCircuitArtifact<BF>,
) -> (DelegationRequestMetadata, DelegationProcessingMetadata) {
    let handle_delegation_requests = cached_data.handle_delegation_requests;
    let process_delegations = cached_data.process_delegations;
    let execute_delegation_argument = cached_data.execute_delegation_argument;
    let delegation_request_layout = cached_data.delegation_request_layout;
    let delegation_processor_layout = cached_data.delegation_processor_layout;
    let memory_timestamp_high_from_circuit_idx = cached_data.memory_timestamp_high_from_circuit_idx;
    let delegation_type = cached_data.delegation_type;
    assert_eq!(
        execute_delegation_argument,
        handle_delegation_requests || process_delegations
    );
    // NB: handle_delegation_requests and process_delegations are mutually exclusive
    if handle_delegation_requests {
        assert!(!process_delegations);
        let layout = delegation_request_layout;
        let request_metadata = DelegationRequestMetadata {
            multiplicity_col: layout.multiplicity.start() as u32,
            timestamp_col: circuit.setup_layout.timestamp_setup_columns.start() as u32,
            memory_timestamp_high_from_circuit_idx,
            delegation_type_col: layout.delegation_type.start() as u32,
            in_cycle_write_idx: BF::from_u64_unchecked(layout.in_cycle_write_index as u64),
            abi_mem_offset_high_col: layout.abi_mem_offset_high.start() as u32,
            has_abi_mem_offset_high: true,
        };
        (request_metadata, DelegationProcessingMetadata::default())
    } else if process_delegations {
        assert!(!handle_delegation_requests); // redundant, for clarity
        let layout = delegation_processor_layout;
        let processing_metadata = DelegationProcessingMetadata {
            multiplicity_col: layout.multiplicity.start() as u32,
            delegation_type,
            write_timestamp_col: layout.write_timestamp.start() as u32,
            abi_mem_offset_high_col: layout.abi_mem_offset_high.start() as u32,
            has_abi_mem_offset_high: true,
        };
        (DelegationRequestMetadata::default(), processing_metadata)
    } else {
        (
            DelegationRequestMetadata::default(),
            DelegationProcessingMetadata::default(),
        )
    }
}

#[derive(Clone, Default)]
#[repr(C)]
pub struct LookupChallenges {
    pub linearization_challenges: [E4; NUM_LOOKUP_ARGUMENT_KEY_PARTS - 1],
    pub gamma: E4,
}

impl LookupChallenges {
    #[allow(dead_code)]
    pub fn new(challenges: &[E4], gamma: E4) -> Self {
        // ensures size matches corresponding cuda struct
        assert_eq!(NUM_LOOKUP_ARGUMENT_KEY_PARTS, 4);
        assert_eq!(challenges.len(), NUM_LOOKUP_ARGUMENT_KEY_PARTS - 1);
        let linearization_challenges: [E4; NUM_LOOKUP_ARGUMENT_KEY_PARTS - 1] =
            std::array::from_fn(|i| challenges[i]);
        Self {
            linearization_challenges,
            gamma,
        }
    }
}

#[derive(Clone, Default)]
#[repr(C)]
pub struct DecoderTableChallenges {
    pub linearization_challenges:
        [E4; EXECUTOR_FAMILY_CIRCUIT_DECODER_TABLE_LINEARIZATION_CHALLENGES],
    pub gamma: E4,
}

impl DecoderTableChallenges {
    #[allow(dead_code)]
    pub fn new(challenges: &[E4], gamma: E4) -> Self {
        // ensures size matches corresponding cuda struct
        assert_eq!(
            EXECUTOR_FAMILY_CIRCUIT_DECODER_TABLE_LINEARIZATION_CHALLENGES,
            9
        );
        assert_eq!(
            challenges.len(),
            EXECUTOR_FAMILY_CIRCUIT_DECODER_TABLE_LINEARIZATION_CHALLENGES,
        );
        let linearization_challenges: [E4;
            EXECUTOR_FAMILY_CIRCUIT_DECODER_TABLE_LINEARIZATION_CHALLENGES] =
            std::array::from_fn(|i| challenges[i]);
        Self {
            linearization_challenges,
            gamma,
        }
    }
}

#[derive(Clone)]
#[repr(C)]
pub struct RangeCheck16ArgsLayout {
    pub num_dst_cols: u32,
    pub src_cols_start: u32,
    pub bf_args_start: u32,
    pub e4_args_start: u32,
    // to be used if num_src_cols is odd, currently not supported on CPU
    // pub maybe_e4_arg_remainder_col: u32,
}

impl RangeCheck16ArgsLayout {
    pub fn new<F: Fn(usize) -> usize>(
        circuit: &CompiledCircuitArtifact<BF>,
        range_check_16_width_1_lookups_access: &Vec<LookupWidth1SourceDestInformation>,
        range_check_16_width_1_lookups_access_via_expressions: &Vec<
            LookupWidth1SourceDestInformationForExpressions<BF>,
        >,
        translate_e4_offset: &F,
    ) -> Self {
        let num_src_cols = circuit.witness_layout.range_check_16_columns.num_elements();
        assert_eq!(num_src_cols % 2, 0);
        let num_dst_cols = num_src_cols / 2;
        let src_cols_start = circuit.witness_layout.range_check_16_columns.start();
        let args_metadata = &circuit.stage_2_layout.intermediate_polys_for_range_check_16;
        assert_eq!(
            num_dst_cols + range_check_16_width_1_lookups_access_via_expressions.len(),
            args_metadata.base_field_oracles.num_elements()
        );
        assert_eq!(
            args_metadata.base_field_oracles.num_elements(),
            args_metadata.ext_4_field_oracles.num_elements()
        );
        let bf_args_start = args_metadata.base_field_oracles.start();
        let e4_args_start = translate_e4_offset(args_metadata.ext_4_field_oracles.start());
        // double-check that expected layout is consistent with layout in CachedData
        assert_eq!(range_check_16_width_1_lookups_access.len(), num_dst_cols);
        for (i, lookup_set) in range_check_16_width_1_lookups_access.iter().enumerate() {
            assert_eq!(lookup_set.a_col, src_cols_start + 2 * i);
            assert_eq!(lookup_set.b_col, src_cols_start + 2 * i + 1);
            assert_eq!(
                lookup_set.base_field_quadratic_oracle_col,
                bf_args_start + i
            );
            assert_eq!(
                translate_e4_offset(lookup_set.ext4_field_inverses_columns_start),
                e4_args_start + i,
            );
        }
        Self {
            num_dst_cols: num_dst_cols as u32,
            src_cols_start: src_cols_start as u32,
            bf_args_start: bf_args_start as u32,
            e4_args_start: e4_args_start as u32,
        }
    }
}

const NUM_STATE_LINKAGE_CONSTRAINTS: usize = 2;

#[derive(Clone)]
#[repr(C)]
pub(crate) struct StateLinkageConstraints {
    pub srcs: [u32; NUM_STATE_LINKAGE_CONSTRAINTS],
    pub dsts: [u32; NUM_STATE_LINKAGE_CONSTRAINTS],
    pub num_constraints: u32,
}

impl StateLinkageConstraints {
    pub fn new(circuit: &CompiledCircuitArtifact<BF>) -> Self {
        let num_constraints = circuit.state_linkage_constraints.len();
        if circuit
            .memory_layout
            .shuffle_ram_inits_and_teardowns
            .is_empty()
        {
            assert_eq!(num_constraints, 0);
        } else {
            assert_eq!(num_constraints, NUM_STATE_LINKAGE_CONSTRAINTS);
        }
        let mut srcs = [0; NUM_STATE_LINKAGE_CONSTRAINTS];
        let mut dsts = [0; NUM_STATE_LINKAGE_CONSTRAINTS];
        for (i, (src, dst)) in circuit.state_linkage_constraints.iter().enumerate() {
            let ColumnAddress::WitnessSubtree(col) = *src else {
                panic!()
            };
            srcs[i] = col as u32;
            let ColumnAddress::WitnessSubtree(col) = *dst else {
                panic!()
            };
            dsts[i] = col as u32;
        }
        Self {
            srcs,
            dsts,
            num_constraints: num_constraints as u32,
        }
    }
}

#[derive(Clone, Default)]
#[repr(C)]
pub struct MemoryChallenges {
    pub address_low_challenge: E4,
    pub address_high_challenge: E4,
    pub timestamp_low_challenge: E4,
    pub timestamp_high_challenge: E4,
    pub value_low_challenge: E4,
    pub value_high_challenge: E4,
    pub gamma: E4,
}

impl MemoryChallenges {
    pub fn new(external_challenges: &ExternalMemoryArgumentChallenges) -> Self {
        let challenges = &external_challenges.memory_argument_linearization_challenges;
        assert_eq!(NUM_MEM_ARGUMENT_KEY_PARTS, 7);
        assert_eq!(challenges.len(), NUM_MEM_ARGUMENT_KEY_PARTS - 1);
        Self {
            address_low_challenge: challenges[MEM_ARGUMENT_CHALLENGE_POWERS_ADDRESS_LOW_IDX],
            address_high_challenge: challenges[MEM_ARGUMENT_CHALLENGE_POWERS_ADDRESS_HIGH_IDX],
            timestamp_low_challenge: challenges[MEM_ARGUMENT_CHALLENGE_POWERS_TIMESTAMP_LOW_IDX],
            timestamp_high_challenge: challenges[MEM_ARGUMENT_CHALLENGE_POWERS_TIMESTAMP_HIGH_IDX],
            value_low_challenge: challenges[MEM_ARGUMENT_CHALLENGE_POWERS_VALUE_LOW_IDX],
            value_high_challenge: challenges[MEM_ARGUMENT_CHALLENGE_POWERS_VALUE_HIGH_IDX],
            gamma: external_challenges.memory_argument_gamma,
        }
    }
}

const MAX_EXPRESSION_PAIRS: usize = 84;
const MAX_EXPRESSIONS: usize = 2 * MAX_EXPRESSION_PAIRS;
const MAX_TERMS_PER_EXPRESSION: usize = 4;
const MAX_EXPRESSION_TERMS: usize = MAX_TERMS_PER_EXPRESSION * MAX_EXPRESSIONS;

#[non_exhaustive]
pub enum ColTypeFlags {}

impl ColTypeFlags {
    #[allow(unused)]
    pub const WITNESS: u16 = 0; // must be 0
    pub const MEMORY: u16 = 1 << 14;
    pub const SETUP: u16 = 1 << 15;
}

#[derive(Clone)]
#[repr(C)]
pub struct TEMPORARYFlattenedLookupExpressionsLayout {
    pub coeffs: [u32; MAX_EXPRESSION_TERMS],
    pub col_idxs: [u16; MAX_EXPRESSION_TERMS],
    pub constant_terms: [BF; MAX_EXPRESSIONS],
    pub num_terms_per_expression: [u8; MAX_EXPRESSIONS],
    pub bf_dst_cols: [u8; MAX_EXPRESSION_PAIRS],
    pub e4_dst_cols: [u8; MAX_EXPRESSION_PAIRS],
    pub num_expression_pairs: u32,
    pub constant_terms_are_zero: bool,
}

impl TEMPORARYFlattenedLookupExpressionsLayout {
    pub fn new<F: Fn(usize) -> usize>(
        expression_pairs: &Vec<LookupWidth1SourceDestInformationForExpressions<BF>>,
        num_stage_2_bf_cols: usize,
        num_stage_2_e4_cols: usize,
        expect_constant_terms_are_zero: bool,
        translate_e4_offset: &F,
    ) -> Self {
        assert!(expression_pairs.len() < MAX_EXPRESSION_PAIRS);
        let mut coeffs = [0 as u32; MAX_EXPRESSION_TERMS];
        let mut col_idxs = [0 as u16; MAX_EXPRESSION_TERMS];
        let mut constant_terms = [BF::ZERO; MAX_EXPRESSIONS];
        let mut num_terms_per_expression = [0 as u8; MAX_EXPRESSIONS];
        let mut bf_dst_cols = [0 as u8; MAX_EXPRESSION_PAIRS];
        let mut e4_dst_cols = [0 as u8; MAX_EXPRESSION_PAIRS];
        let mut constant_terms_are_zero: bool = true;
        let mut expression_idx: usize = 0;
        let mut flat_term_idx: usize = 0;
        let mut stash_expr = |expr: &LookupExpression<BF>,
                              expression_idx: &mut usize,
                              flat_term_idx: &mut usize,
                              constant_terms_are_zero: &mut bool| {
            let LookupExpression::Expression(a) = expr else {
                unreachable!()
            };
            let num_terms = a.linear_terms.len();
            assert!(num_terms > 0);
            assert!(num_terms <= MAX_TERMS_PER_EXPRESSION);
            if expect_constant_terms_are_zero {
                assert_eq!(a.constant_term, BF::ZERO);
            } else {
                if a.constant_term != BF::ZERO {
                    *constant_terms_are_zero = false;
                }
                constant_terms[*expression_idx] = a.constant_term;
            };
            num_terms_per_expression[*expression_idx] = u8::try_from(num_terms).unwrap();
            for (coeff, column_address) in a.linear_terms.iter() {
                coeffs[*flat_term_idx] = coeff.0;
                col_idxs[*flat_term_idx] = match column_address {
                    ColumnAddress::WitnessSubtree(col) => *col as u16,
                    ColumnAddress::MemorySubtree(col) => (*col as u16) | ColTypeFlags::MEMORY,
                    _ => panic!(
                        "Non-shuffle-ram expressions are expected to use witness and memory cols only",
                    ),
                };
                *flat_term_idx = *flat_term_idx + 1;
            }
            *expression_idx = *expression_idx + 1;
        };
        let mut i = 0; // expression pair idx
        for lookup_set in expression_pairs.iter() {
            stash_expr(
                &lookup_set.a_expr,
                &mut expression_idx,
                &mut flat_term_idx,
                &mut constant_terms_are_zero,
            );
            stash_expr(
                &lookup_set.b_expr,
                &mut expression_idx,
                &mut flat_term_idx,
                &mut constant_terms_are_zero,
            );
            let bf_dst_col = lookup_set.base_field_quadratic_oracle_col;
            assert!(bf_dst_col < num_stage_2_bf_cols);
            bf_dst_cols[i] = u8::try_from(bf_dst_col).unwrap();
            let e4_dst_col = translate_e4_offset(lookup_set.ext4_field_inverses_columns_start);
            assert!(e4_dst_col < num_stage_2_e4_cols);
            e4_dst_cols[i] = u8::try_from(e4_dst_col).unwrap();
            i += 1;
        }
        // assert_eq!(timestamp_constant_terms_are_zero, true); // just testing a theory
        Self {
            coeffs,
            col_idxs,
            constant_terms,
            num_terms_per_expression,
            bf_dst_cols,
            e4_dst_cols,
            num_expression_pairs: expression_pairs.len() as u32,
            constant_terms_are_zero,
        }
    }
}

impl Default for TEMPORARYFlattenedLookupExpressionsLayout {
    fn default() -> Self {
        Self {
            coeffs: [0; MAX_EXPRESSION_TERMS],
            col_idxs: [0; MAX_EXPRESSION_TERMS],
            constant_terms: [BF::ZERO; MAX_EXPRESSIONS],
            num_terms_per_expression: [0; MAX_EXPRESSIONS],
            bf_dst_cols: [0; MAX_EXPRESSION_PAIRS],
            e4_dst_cols: [0; MAX_EXPRESSION_PAIRS],
            num_expression_pairs: 0,
            constant_terms_are_zero: true,
        }
    }
}

// We expect (and assert) that non-shuffle-ram expressions have constant_term = 0
// and use only memory and witness (not setup) columns.
// temporary, to support stage 3 while i refactor stage 2
#[derive(Clone)]
#[repr(C)]
pub struct FlattenedLookupExpressionsLayout {
    pub coeffs: [u32; MAX_EXPRESSION_TERMS],
    pub col_idxs: [u16; MAX_EXPRESSION_TERMS],
    pub constant_terms: [BF; MAX_EXPRESSIONS],
    pub num_terms_per_expression: [u8; MAX_EXPRESSIONS],
    pub bf_dst_cols: [u8; MAX_EXPRESSION_PAIRS],
    pub e4_dst_cols: [u8; MAX_EXPRESSION_PAIRS],
    pub num_range_check_16_expression_pairs: u32,
    pub num_timestamp_expression_pairs: u32,
    pub range_check_16_constant_terms_are_zero: bool,
    pub timestamp_constant_terms_are_zero: bool,
}

impl FlattenedLookupExpressionsLayout {
    pub fn new<F: Fn(usize) -> usize>(
        range_check_16_expression_pairs: &Vec<LookupWidth1SourceDestInformationForExpressions<BF>>,
        timestamp_expression_pairs: &Vec<LookupWidth1SourceDestInformationForExpressions<BF>>,
        num_stage_2_bf_cols: usize,
        num_stage_2_e4_cols: usize,
        expect_constant_terms_are_zero: bool,
        translate_e4_offset: &F,
    ) -> Self {
        assert!(
            range_check_16_expression_pairs.len() + timestamp_expression_pairs.len()
                < MAX_EXPRESSION_PAIRS
        );
        // safer to check each individual conversion
        // assert!(num_stage_2_bf_cols <= u8::MAX as usize);
        // assert!(num_stage_2_e4_cols <= u8::MAX as usize);
        let mut coeffs = [0 as u32; MAX_EXPRESSION_TERMS];
        let mut col_idxs = [0 as u16; MAX_EXPRESSION_TERMS];
        let mut constant_terms = [BF::ZERO; MAX_EXPRESSIONS];
        let mut num_terms_per_expression = [0 as u8; MAX_EXPRESSIONS];
        let mut bf_dst_cols = [0 as u8; MAX_EXPRESSION_PAIRS];
        let mut e4_dst_cols = [0 as u8; MAX_EXPRESSION_PAIRS];
        let mut range_check_16_constant_terms_are_zero: bool = true;
        let mut timestamp_constant_terms_are_zero: bool = true;
        let mut expression_idx: usize = 0;
        let mut flat_term_idx: usize = 0;
        let mut stash_expr = |expr: &LookupExpression<BF>,
                              expression_idx: &mut usize,
                              flat_term_idx: &mut usize,
                              constant_terms_are_zero: &mut bool| {
            let LookupExpression::Expression(a) = expr else {
                unreachable!()
            };
            let num_terms = a.linear_terms.len();
            assert!(num_terms > 0);
            assert!(num_terms <= MAX_TERMS_PER_EXPRESSION);
            if expect_constant_terms_are_zero {
                assert_eq!(a.constant_term, BF::ZERO);
            } else {
                if a.constant_term != BF::ZERO {
                    *constant_terms_are_zero = false;
                }
                constant_terms[*expression_idx] = a.constant_term;
            };
            num_terms_per_expression[*expression_idx] = u8::try_from(num_terms).unwrap();
            for (coeff, column_address) in a.linear_terms.iter() {
                coeffs[*flat_term_idx] = coeff.0;
                col_idxs[*flat_term_idx] = match column_address {
                    ColumnAddress::WitnessSubtree(col) => *col as u16,
                    ColumnAddress::MemorySubtree(col) => (*col as u16) | ColTypeFlags::MEMORY,
                    _ => panic!(
                        "Non-shuffle-ram expressions are expected to use witness and memory cols only",
                    ),
                };
                *flat_term_idx = *flat_term_idx + 1;
            }
            *expression_idx = *expression_idx + 1;
        };
        let mut i = 0; // expression pair idx
        for lookup_set in range_check_16_expression_pairs.iter() {
            stash_expr(
                &lookup_set.a_expr,
                &mut expression_idx,
                &mut flat_term_idx,
                &mut range_check_16_constant_terms_are_zero,
            );
            stash_expr(
                &lookup_set.b_expr,
                &mut expression_idx,
                &mut flat_term_idx,
                &mut range_check_16_constant_terms_are_zero,
            );
            let bf_dst_col = lookup_set.base_field_quadratic_oracle_col;
            assert!(bf_dst_col < num_stage_2_bf_cols);
            bf_dst_cols[i] = u8::try_from(bf_dst_col).unwrap();
            let e4_dst_col = translate_e4_offset(lookup_set.ext4_field_inverses_columns_start);
            assert!(e4_dst_col < num_stage_2_e4_cols);
            e4_dst_cols[i] = u8::try_from(e4_dst_col).unwrap();
            i += 1;
        }
        for lookup_set in timestamp_expression_pairs.iter() {
            stash_expr(
                &lookup_set.a_expr,
                &mut expression_idx,
                &mut flat_term_idx,
                &mut timestamp_constant_terms_are_zero,
            );
            stash_expr(
                &lookup_set.b_expr,
                &mut expression_idx,
                &mut flat_term_idx,
                &mut timestamp_constant_terms_are_zero,
            );
            let bf_dst_col = lookup_set.base_field_quadratic_oracle_col;
            assert!(bf_dst_col < num_stage_2_bf_cols);
            bf_dst_cols[i] = u8::try_from(bf_dst_col).unwrap();
            let e4_dst_col = translate_e4_offset(lookup_set.ext4_field_inverses_columns_start);
            assert!(e4_dst_col < num_stage_2_e4_cols);
            e4_dst_cols[i] = u8::try_from(e4_dst_col).unwrap();
            i += 1;
        }
        // assert_eq!(timestamp_constant_terms_are_zero, true); // just testing a theory
        Self {
            coeffs,
            col_idxs,
            constant_terms,
            num_terms_per_expression,
            bf_dst_cols,
            e4_dst_cols,
            num_range_check_16_expression_pairs: range_check_16_expression_pairs.len() as u32,
            num_timestamp_expression_pairs: timestamp_expression_pairs.len() as u32,
            range_check_16_constant_terms_are_zero,
            timestamp_constant_terms_are_zero,
        }
    }
}

impl Default for FlattenedLookupExpressionsLayout {
    fn default() -> Self {
        Self {
            coeffs: [0; MAX_EXPRESSION_TERMS],
            col_idxs: [0; MAX_EXPRESSION_TERMS],
            constant_terms: [BF::ZERO; MAX_EXPRESSIONS],
            num_terms_per_expression: [0; MAX_EXPRESSIONS],
            bf_dst_cols: [0; MAX_EXPRESSION_PAIRS],
            e4_dst_cols: [0; MAX_EXPRESSION_PAIRS],
            num_range_check_16_expression_pairs: 0,
            num_timestamp_expression_pairs: 0,
            range_check_16_constant_terms_are_zero: true,
            timestamp_constant_terms_are_zero: true,
        }
    }
}

const MAX_EXPRESSION_PAIRS_FOR_SHUFFLE_RAM: usize = 4;
const MAX_EXPRESSIONS_FOR_SHUFFLE_RAM: usize = 2 * MAX_EXPRESSION_PAIRS_FOR_SHUFFLE_RAM;
const MAX_EXPRESSION_TERMS_FOR_SHUFFLE_RAM: usize =
    MAX_TERMS_PER_EXPRESSION * MAX_EXPRESSIONS_FOR_SHUFFLE_RAM;

// Each shuffle ram lookup expressions may have a nonzero constant_term.
// Each column may be witness, memory, or setup.
#[derive(Clone)]
#[repr(C)]
pub struct FlattenedLookupExpressionsForShuffleRamLayout {
    pub coeffs: [u32; MAX_EXPRESSION_TERMS_FOR_SHUFFLE_RAM],
    pub col_idxs: [u16; MAX_EXPRESSION_TERMS_FOR_SHUFFLE_RAM],
    pub constant_terms: [BF; MAX_EXPRESSIONS_FOR_SHUFFLE_RAM],
    pub num_terms_per_expression: [u8; MAX_EXPRESSIONS_FOR_SHUFFLE_RAM],
    pub bf_dst_cols: [u8; MAX_EXPRESSION_PAIRS_FOR_SHUFFLE_RAM],
    pub e4_dst_cols: [u8; MAX_EXPRESSION_PAIRS_FOR_SHUFFLE_RAM],
    pub num_expression_pairs: u32,
}

impl FlattenedLookupExpressionsForShuffleRamLayout {
    pub fn new<F: Fn(usize) -> usize>(
        expression_pairs: &Vec<LookupWidth1SourceDestInformationForExpressions<BF>>,
        num_stage_2_bf_cols: usize,
        num_stage_2_e4_cols: usize,
        translate_e4_offset: &F,
    ) -> Self {
        assert!(expression_pairs.len() <= MAX_EXPRESSION_PAIRS_FOR_SHUFFLE_RAM);
        // safer to check each individual conversion
        // assert!(num_stage_2_bf_cols <= u8::MAX as usize);
        // assert!(num_stage_2_e4_cols <= u8::MAX as usize);
        let mut coeffs = [0 as u32; MAX_EXPRESSION_TERMS_FOR_SHUFFLE_RAM];
        let mut col_idxs = [0 as u16; MAX_EXPRESSION_TERMS_FOR_SHUFFLE_RAM];
        let mut constant_terms = [BF::ZERO; MAX_EXPRESSIONS_FOR_SHUFFLE_RAM];
        let mut num_terms_per_expression = [0 as u8; MAX_EXPRESSIONS_FOR_SHUFFLE_RAM];
        let mut bf_dst_cols = [0 as u8; MAX_EXPRESSION_PAIRS_FOR_SHUFFLE_RAM];
        let mut e4_dst_cols = [0 as u8; MAX_EXPRESSION_PAIRS_FOR_SHUFFLE_RAM];
        let mut expression_idx: usize = 0;
        let mut flat_term_idx: usize = 0;
        let mut stash_expr = |expr: &LookupExpression<BF>,
                              expression_idx: &mut usize,
                              flat_term_idx: &mut usize| {
            let LookupExpression::Expression(a) = expr else {
                unreachable!()
            };
            let num_terms = a.linear_terms.len();
            assert!(num_terms > 0);
            assert!(num_terms <= MAX_TERMS_PER_EXPRESSION);
            constant_terms[*expression_idx] = a.constant_term;
            num_terms_per_expression[*expression_idx] = u8::try_from(num_terms).unwrap();
            for (coeff, column_address) in a.linear_terms.iter() {
                coeffs[*flat_term_idx] = coeff.0;
                col_idxs[*flat_term_idx] = match column_address {
                    ColumnAddress::WitnessSubtree(col) => *col as u16,
                    ColumnAddress::MemorySubtree(col) => (*col as u16) | ColTypeFlags::MEMORY,
                    ColumnAddress::SetupSubtree(col) => (*col as u16) | ColTypeFlags::SETUP,
                    _ => panic!(
                        "Non-shuffle-ram expressions are expected to use witness and memory cols only",
                    ),
                };
                *flat_term_idx = *flat_term_idx + 1;
            }
            *expression_idx = *expression_idx + 1;
        };
        for (i, lookup_set) in expression_pairs.iter().enumerate() {
            stash_expr(&lookup_set.a_expr, &mut expression_idx, &mut flat_term_idx);
            stash_expr(&lookup_set.b_expr, &mut expression_idx, &mut flat_term_idx);
            let bf_dst_col = lookup_set.base_field_quadratic_oracle_col;
            assert!(bf_dst_col < num_stage_2_bf_cols);
            bf_dst_cols[i] = u8::try_from(bf_dst_col).unwrap();
            let e4_dst_col = translate_e4_offset(lookup_set.ext4_field_inverses_columns_start);
            assert!(e4_dst_col < num_stage_2_e4_cols);
            e4_dst_cols[i] = u8::try_from(e4_dst_col).unwrap();
        }
        Self {
            coeffs,
            col_idxs,
            constant_terms,
            num_terms_per_expression,
            bf_dst_cols,
            e4_dst_cols,
            num_expression_pairs: expression_pairs.len() as u32,
        }
    }
}

impl Default for FlattenedLookupExpressionsForShuffleRamLayout {
    fn default() -> Self {
        Self {
            coeffs: [0; MAX_EXPRESSION_TERMS_FOR_SHUFFLE_RAM],
            col_idxs: [0; MAX_EXPRESSION_TERMS_FOR_SHUFFLE_RAM],
            constant_terms: [BF::ZERO; MAX_EXPRESSIONS_FOR_SHUFFLE_RAM],
            num_terms_per_expression: [0; MAX_EXPRESSIONS_FOR_SHUFFLE_RAM],
            bf_dst_cols: [0; MAX_EXPRESSION_PAIRS_FOR_SHUFFLE_RAM],
            e4_dst_cols: [0; MAX_EXPRESSION_PAIRS_FOR_SHUFFLE_RAM],
            num_expression_pairs: 0,
        }
    }
}

#[derive(Clone, Copy, Default)]
#[repr(C)]
pub struct LazyInitTeardownLayout {
    pub init_address_start: u32,
    pub teardown_value_start: u32,
    pub teardown_timestamp_start: u32,
    pub init_address_aux_low: u32,
    pub init_address_aux_high: u32,
    pub init_address_intermediate_borrow: u32,
    pub init_address_final_borrow: u32,
    pub bf_arg_col: u32,
    pub e4_arg_col: u32,
}

pub const MAX_LAZY_INIT_TEARDOWN_SETS: usize = 16;

#[derive(Clone)]
#[repr(C)]
pub struct LazyInitTeardownLayouts {
    pub layouts: [LazyInitTeardownLayout; MAX_LAZY_INIT_TEARDOWN_SETS],
    pub num_init_teardown_sets: u32,
    pub grand_product_contributions_start: u32,
    pub process_shuffle_ram_init: bool,
}

impl LazyInitTeardownLayouts {
    fn unpack_witness_column_address(column_address: ColumnAddress) -> usize {
        if let ColumnAddress::WitnessSubtree(col) = column_address {
            col
        } else {
            panic!("shuffle ram aux helpers should be in witness")
        }
    }

    pub fn new<F: Fn(usize) -> usize>(
        circuit: &CompiledCircuitArtifact<BF>,
        lookup_set: &OptimizedOraclesForLookupWidth1,
        shuffle_ram_inits_and_teardowns: &Vec<ShuffleRamInitAndTeardownLayout>,
        translate_e4_offset: &F,
    ) -> Self {
        let lazy_init_address_aux_vars = &circuit.lazy_init_address_aux_vars;
        let num_init_teardown_sets = shuffle_ram_inits_and_teardowns.len();
        assert!(num_init_teardown_sets <= MAX_LAZY_INIT_TEARDOWN_SETS);
        assert_eq!(num_init_teardown_sets, lazy_init_address_aux_vars.len());
        assert_eq!(
            num_init_teardown_sets,
            lookup_set.base_field_oracles.num_elements()
        );
        assert_eq!(
            num_init_teardown_sets,
            lookup_set.ext_4_field_oracles.num_elements()
        );
        let intermediate_polys_for_memory_init_teardown = &circuit
            .stage_2_layout
            .intermediate_polys_for_memory_init_teardown;
        assert_eq!(
            num_init_teardown_sets,
            intermediate_polys_for_memory_init_teardown.num_elements(),
        );
        let grand_product_contributions_start =
            translate_e4_offset(intermediate_polys_for_memory_init_teardown.start()) as u32;
        let mut layouts = [LazyInitTeardownLayout::default(); MAX_LAZY_INIT_TEARDOWN_SETS];
        for (i, (init_and_teardown, aux_vars)) in shuffle_ram_inits_and_teardowns
            .iter()
            .zip(lazy_init_address_aux_vars.iter())
            .enumerate()
        {
            let init_address_start = init_and_teardown.lazy_init_addresses_columns.start();
            let teardown_value_start = init_and_teardown.lazy_teardown_values_columns.start();
            let teardown_timestamp_start =
                init_and_teardown.lazy_teardown_timestamps_columns.start();
            let ShuffleRamAuxComparisonSet {
                aux_low_high: [address_aux_low, address_aux_high],
                intermediate_borrow,
                final_borrow,
            } = aux_vars;
            let init_address_aux_low = Self::unpack_witness_column_address(*address_aux_low);
            let init_address_aux_high = Self::unpack_witness_column_address(*address_aux_high);
            let intermediate_borrow = Self::unpack_witness_column_address(*intermediate_borrow);
            let final_borrow = Self::unpack_witness_column_address(*final_borrow);
            layouts[i] = LazyInitTeardownLayout {
                init_address_start: init_address_start as u32,
                teardown_value_start: teardown_value_start as u32,
                teardown_timestamp_start: teardown_timestamp_start as u32,
                init_address_aux_low: init_address_aux_low as u32,
                init_address_aux_high: init_address_aux_high as u32,
                init_address_intermediate_borrow: intermediate_borrow as u32,
                init_address_final_borrow: final_borrow as u32,
                bf_arg_col: (lookup_set.base_field_oracles.start() + i) as u32,
                e4_arg_col: translate_e4_offset(lookup_set.ext_4_field_oracles.start() + 4 * i)
                    as u32,
            }
        }
        Self {
            layouts,
            num_init_teardown_sets: num_init_teardown_sets as u32,
            grand_product_contributions_start,
            process_shuffle_ram_init: true,
        }
    }
}

impl Default for LazyInitTeardownLayouts {
    fn default() -> Self {
        Self {
            layouts: [LazyInitTeardownLayout::default(); MAX_LAZY_INIT_TEARDOWN_SETS],
            num_init_teardown_sets: 0,
            grand_product_contributions_start: 0,
            process_shuffle_ram_init: false,
        }
    }
}

#[derive(Clone)]
#[repr(C)]
pub struct MachineStateLayout {
    pub initial_pc_start: u32,
    pub initial_timestamp_start: u32,
    pub final_pc_start: u32,
    pub final_timestamp_start: u32,
    pub arg_col: u32,
    pub process_machine_state: bool,
}

impl MachineStateLayout {
    pub fn new<F: Fn(usize) -> usize>(
        circuit: &CompiledCircuitArtifact<BF>,
        translate_e4_offset: &F,
    ) -> Self {
        let initial_machine_state = &circuit.memory_layout.intermediate_state_layout;
        let final_machine_state = &circuit.memory_layout.machine_state_layout;
        let intermediate_polys_for_state_permutation = &circuit
            .stage_2_layout
            .intermediate_polys_for_state_permutation;
        if intermediate_polys_for_state_permutation.num_elements() > 0 {
            assert_eq!(intermediate_polys_for_state_permutation.num_elements(), 1);
            let initial_machine_state = initial_machine_state.as_ref().unwrap();
            let final_machine_state = final_machine_state.as_ref().unwrap();
            return Self {
                initial_pc_start: initial_machine_state.pc.start() as u32,
                initial_timestamp_start: initial_machine_state.timestamp.start() as u32,
                final_pc_start: final_machine_state.pc.start() as u32,
                final_timestamp_start: final_machine_state.timestamp.start() as u32,
                arg_col: translate_e4_offset(intermediate_polys_for_state_permutation.start())
                    as u32,
                process_machine_state: true,
            };
        }
        assert!(initial_machine_state.is_none());
        assert!(final_machine_state.is_none());
        Self::default()
    }
}

impl Default for MachineStateLayout {
    fn default() -> Self {
        Self {
            initial_pc_start: 0,
            initial_timestamp_start: 0,
            final_pc_start: 0,
            final_timestamp_start: 0,
            arg_col: 0,
            process_machine_state: false,
        }
    }
}

#[derive(Clone, Copy, Default)]
#[repr(C)]
pub struct ShuffleRamAccess {
    pub address_start: u32,
    pub read_timestamp_start: u32,
    pub read_value_start: u32,
    pub maybe_write_value_start: u32,
    pub maybe_is_register_start: u32,
    pub is_write: bool,
    pub is_register_only: bool,
}

const MAX_SHUFFLE_RAM_ACCESSES: usize = 3;

#[derive(Clone)]
#[repr(C)]
pub struct ShuffleRamAccesses {
    pub accesses: [ShuffleRamAccess; MAX_SHUFFLE_RAM_ACCESSES],
    pub num_accesses: u32,
    pub write_timestamp_start: u32,
}

impl ShuffleRamAccesses {
    pub fn new(
        shuffle_ram_access_sets: &Vec<ShuffleRamQueryColumns>,
        write_timestamp_start: usize,
    ) -> Self {
        let mut accesses = [ShuffleRamAccess::default(); MAX_SHUFFLE_RAM_ACCESSES];
        let num_accesses = shuffle_ram_access_sets.len();
        assert!(num_accesses <= MAX_SHUFFLE_RAM_ACCESSES);
        // imitates zksync_airbender's stage2.rs
        for (i, memory_access_columns) in shuffle_ram_access_sets.iter().enumerate() {
            match memory_access_columns {
                ShuffleRamQueryColumns::Readonly(columns) => {
                    let (is_register_only, address_start, maybe_is_register_start) =
                        match memory_access_columns.get_address() {
                            ShuffleRamAddress::RegisterOnly(RegisterOnlyAccessAddress {
                                register_index,
                            }) => (true, register_index.start(), 0),
                            ShuffleRamAddress::RegisterOrRam(RegisterOrRamAccessAddress {
                                is_register,
                                address,
                            }) => (false, address.start(), is_register.start()),
                        };
                    accesses[i] = ShuffleRamAccess {
                        address_start: address_start as u32,
                        read_timestamp_start: columns.read_timestamp.start() as u32,
                        read_value_start: columns.read_value.start() as u32,
                        maybe_write_value_start: 0,
                        maybe_is_register_start: maybe_is_register_start as u32,
                        is_write: false,
                        is_register_only,
                    };
                }
                ShuffleRamQueryColumns::Write(columns) => {
                    let (is_register_only, address_start, maybe_is_register_start) =
                        match memory_access_columns.get_address() {
                            ShuffleRamAddress::RegisterOnly(RegisterOnlyAccessAddress {
                                register_index,
                            }) => (true, register_index.start(), 0),
                            ShuffleRamAddress::RegisterOrRam(RegisterOrRamAccessAddress {
                                is_register,
                                address,
                            }) => (false, address.start(), is_register.start()),
                        };
                    accesses[i] = ShuffleRamAccess {
                        address_start: address_start as u32,
                        read_timestamp_start: columns.read_timestamp.start() as u32,
                        read_value_start: columns.read_value.start() as u32,
                        maybe_write_value_start: columns.write_value.start() as u32,
                        maybe_is_register_start: maybe_is_register_start as u32,
                        is_write: true,
                        is_register_only,
                    };
                }
                #[allow(unreachable_patterns)]
                _ => unreachable!("Unexpected ShuffleRamQueryColumns variant"),
            }
        }
        Self {
            accesses,
            num_accesses: num_accesses as u32,
            write_timestamp_start: write_timestamp_start as u32,
        }
    }
}

impl Default for ShuffleRamAccesses {
    fn default() -> Self {
        Self {
            accesses: [ShuffleRamAccess::default(); MAX_SHUFFLE_RAM_ACCESSES],
            num_accesses: 0,
            write_timestamp_start: 0,
        }
    }
}

#[derive(Clone, Copy, Default)]
#[repr(C)]
pub struct RegisterAccess {
    pub gamma_plus_one_plus_address_low_contribution: E4,
    pub read_timestamp_col: u32,
    pub read_value_col: u32,
    pub maybe_write_value_col: u32,
    pub is_write: bool,
}

#[derive(Clone, Copy, Default)]
#[repr(C)]
pub struct IndirectAccess {
    pub read_timestamp_col: u32,
    pub read_value_col: u32,
    pub maybe_write_value_col: u32,
    pub maybe_address_derivation_carry_bit_col: u32,
    pub maybe_variable_dependent_coeff: u32,
    pub maybe_variable_dependent_col: u32,
    pub offset_constant: u32,
    pub has_address_derivation_carry_bit: bool,
    pub has_variable_dependent: bool,
    pub has_write: bool,
}

pub const MAX_REGISTER_ACCESSES: usize = 4;
pub const MAX_INDIRECT_ACCESSES: usize = 40;

#[derive(Clone)]
#[repr(C)]
pub struct RegisterAndIndirectAccesses {
    pub register_accesses: [RegisterAccess; MAX_REGISTER_ACCESSES],
    pub indirect_accesses: [IndirectAccess; MAX_INDIRECT_ACCESSES],
    pub indirect_accesses_per_register_access: [u32; MAX_REGISTER_ACCESSES],
    pub num_register_accesses: u32,
    pub write_timestamp_col: u32,
}

impl RegisterAndIndirectAccesses {
    pub fn new(
        challenges: &MemoryChallenges,
        register_and_indirect_accesses: &Vec<RegisterAndIndirectAccessDescription>,
        write_timestamp_col: usize,
    ) -> Self {
        assert_eq!(NUM_TIMESTAMP_COLUMNS_FOR_RAM, 2);
        assert_eq!(REGISTER_SIZE, 2);
        let mut register_accesses = [RegisterAccess::default(); MAX_REGISTER_ACCESSES];
        let mut indirect_accesses = [IndirectAccess::default(); MAX_INDIRECT_ACCESSES];
        let mut indirect_accesses_per_register_access = [0; MAX_REGISTER_ACCESSES];
        let num_register_accesses = register_and_indirect_accesses.len();
        assert!(num_register_accesses <= MAX_REGISTER_ACCESSES);
        let mut flat_indirect_idx = 0;
        for (i, register_access_columns) in register_and_indirect_accesses.iter().enumerate() {
            match register_access_columns.register_access {
                RegisterAccessColumns::ReadAccess {
                    read_timestamp,
                    read_value,
                    register_index,
                } => {
                    let address_low = BF::from_u64_unchecked(register_index as u64);
                    let mut gamma_plus_one_plus_address_low_contribution =
                        challenges.address_low_challenge.clone();
                    gamma_plus_one_plus_address_low_contribution.mul_assign_by_base(&address_low);
                    gamma_plus_one_plus_address_low_contribution.add_assign_base(&BF::ONE);
                    gamma_plus_one_plus_address_low_contribution.add_assign(&challenges.gamma);
                    register_accesses[i] = RegisterAccess {
                        gamma_plus_one_plus_address_low_contribution,
                        read_timestamp_col: read_timestamp.start() as u32,
                        read_value_col: read_value.start() as u32,
                        maybe_write_value_col: 0,
                        is_write: false,
                    };
                }
                RegisterAccessColumns::WriteAccess {
                    read_timestamp,
                    read_value,
                    write_value,
                    register_index,
                } => {
                    let address_low = BF::from_u64_unchecked(register_index as u64);
                    let mut gamma_plus_one_plus_address_low_contribution =
                        challenges.address_low_challenge.clone();
                    gamma_plus_one_plus_address_low_contribution.mul_assign_by_base(&address_low);
                    gamma_plus_one_plus_address_low_contribution.add_assign_base(&BF::ONE);
                    gamma_plus_one_plus_address_low_contribution.add_assign(&challenges.gamma);
                    register_accesses[i] = RegisterAccess {
                        gamma_plus_one_plus_address_low_contribution,
                        read_timestamp_col: read_timestamp.start() as u32,
                        read_value_col: read_value.start() as u32,
                        maybe_write_value_col: write_value.start() as u32,
                        is_write: true,
                    };
                }
                #[allow(unreachable_patterns)]
                _ => unreachable!("Unexpected RegisterAccessColumns variant"),
            }
            indirect_accesses_per_register_access[i] =
                register_access_columns.indirect_accesses.len() as u32;
            for (j, indirect_access_columns) in
                register_access_columns.indirect_accesses.iter().enumerate()
            {
                match indirect_access_columns {
                    IndirectAccessColumns::ReadAccess {
                        read_timestamp,
                        read_value,
                        address_derivation_carry_bit,
                        variable_dependent,
                        offset_constant,
                    } => {
                        let has_address_derivation_carry_bit =
                            address_derivation_carry_bit.num_elements() > 0;
                        if has_address_derivation_carry_bit {
                            assert_eq!(address_derivation_carry_bit.num_elements(), 1);
                        }
                        // The following asserts are sanity checks
                        // based on our known circuit geometries
                        // (slightly different from WriteAccess arm below).
                        assert_eq!(j == 0, *offset_constant == 0);
                        if j == 0 {
                            assert!(!has_address_derivation_carry_bit);
                        }
                        if has_address_derivation_carry_bit {
                            assert!(variable_dependent.is_none());
                        }
                        let maybe_address_derivation_carry_bit_col =
                            if has_address_derivation_carry_bit {
                                address_derivation_carry_bit.start() as u32
                            } else {
                                0
                            };
                        let (
                            maybe_variable_dependent_coeff,
                            maybe_variable_dependent_col,
                            has_variable_dependent,
                        ) = if let Some((coeff, col, _)) = variable_dependent {
                            (*coeff, col.start() as u32, true)
                        } else {
                            (0, 0, false)
                        };
                        indirect_accesses[flat_indirect_idx] = IndirectAccess {
                            read_timestamp_col: read_timestamp.start() as u32,
                            read_value_col: read_value.start() as u32,
                            maybe_write_value_col: 0,
                            maybe_address_derivation_carry_bit_col,
                            maybe_variable_dependent_coeff,
                            maybe_variable_dependent_col,
                            offset_constant: *offset_constant,
                            has_address_derivation_carry_bit,
                            has_variable_dependent,
                            has_write: false,
                        };
                    }
                    IndirectAccessColumns::WriteAccess {
                        read_timestamp,
                        read_value,
                        write_value,
                        address_derivation_carry_bit,
                        variable_dependent,
                        offset_constant,
                    } => {
                        let has_address_derivation_carry_bit =
                            address_derivation_carry_bit.num_elements() > 0;
                        if has_address_derivation_carry_bit {
                            assert_eq!(address_derivation_carry_bit.num_elements(), 1);
                        }
                        // The following asserts are sanity checks
                        // based on our known circuit geometries
                        // (slightly different from ReadAccess arm above).
                        if j == 0 {
                            assert!(!has_address_derivation_carry_bit);
                            assert_eq!(*offset_constant, 0);
                        }
                        if has_address_derivation_carry_bit {
                            assert!(variable_dependent.is_none());
                        }
                        let maybe_address_derivation_carry_bit_col =
                            if has_address_derivation_carry_bit {
                                address_derivation_carry_bit.start() as u32
                            } else {
                                0
                            };
                        let (
                            maybe_variable_dependent_coeff,
                            maybe_variable_dependent_col,
                            has_variable_dependent,
                        ) = if let Some((coeff, col, _)) = variable_dependent {
                            (*coeff, col.start() as u32, true)
                        } else {
                            (0, 0, false)
                        };
                        indirect_accesses[flat_indirect_idx] = IndirectAccess {
                            read_timestamp_col: read_timestamp.start() as u32,
                            read_value_col: read_value.start() as u32,
                            maybe_write_value_col: write_value.start() as u32,
                            maybe_address_derivation_carry_bit_col,
                            maybe_variable_dependent_coeff,
                            maybe_variable_dependent_col,
                            offset_constant: *offset_constant,
                            has_address_derivation_carry_bit,
                            has_variable_dependent,
                            has_write: true,
                        };
                    }
                    #[allow(unreachable_patterns)]
                    _ => unreachable!("Unexpected IndirectAccessColumns variant"),
                }
                flat_indirect_idx += 1;
            }
        }
        Self {
            register_accesses,
            indirect_accesses,
            indirect_accesses_per_register_access,
            num_register_accesses: num_register_accesses as u32,
            write_timestamp_col: write_timestamp_col as u32,
        }
    }
}

impl Default for RegisterAndIndirectAccesses {
    fn default() -> Self {
        Self {
            register_accesses: [RegisterAccess::default(); MAX_REGISTER_ACCESSES],
            indirect_accesses: [IndirectAccess::default(); MAX_INDIRECT_ACCESSES],
            indirect_accesses_per_register_access: [0; MAX_REGISTER_ACCESSES],
            num_register_accesses: 0,
            write_timestamp_col: 0,
        }
    }
}

pub fn print_size<T>(name: &str) -> usize {
    let size = size_of::<T>();
    println!("{}: {}", name, size);
    size
}

pub fn get_grand_product_src_dst_cols(
    circuit: &CompiledCircuitArtifact<BF>,
    unrolled: bool,
) -> (usize, usize) {
    let e4_cols_offset = circuit.stage_2_layout.ext4_polys_offset;
    assert_eq!(e4_cols_offset % 4, 0);
    let translate_e4_offset = |raw_col: usize| -> usize {
        assert_eq!(raw_col % 4, 0);
        assert!(raw_col >= e4_cols_offset);
        (raw_col - e4_cols_offset) / 4
    };
    let raw_grand_product_dst = circuit
        .stage_2_layout
        .intermediate_poly_for_grand_product
        .start();
    let grand_product_dst = translate_e4_offset(raw_grand_product_dst);
    if unrolled {
        let mut grand_product_src = usize::MAX;
        let precedence = [
            &circuit
                .stage_2_layout
                .intermediate_polys_for_memory_init_teardown,
            &circuit
                .stage_2_layout
                .intermediate_polys_for_permutation_masking,
            &circuit
                .stage_2_layout
                .intermediate_polys_for_state_permutation,
            &circuit
                .stage_2_layout
                .intermediate_polys_for_memory_argument,
        ];
        for next in precedence.iter() {
            if next.num_elements() > 0 {
                grand_product_src = translate_e4_offset(next.start());
                grand_product_src += next.num_elements() - 1;
                break;
            }
        }
        assert!(grand_product_src != usize::MAX);
        return (grand_product_src, grand_product_dst);
    }
    let memory_args = &circuit
        .stage_2_layout
        .intermediate_polys_for_memory_argument;
    assert!(memory_args.num_elements() > 0);
    let mut grand_product_src = usize::MAX;
    let precedence = [
        &circuit
            .stage_2_layout
            .intermediate_polys_for_memory_init_teardown,
        memory_args,
    ];
    for next in precedence.iter() {
        if next.num_elements() > 0 {
            grand_product_src = translate_e4_offset(next.start());
            grand_product_src += next.num_elements() - 1;
            break;
        }
    }
    assert!(grand_product_src != usize::MAX);
    (grand_product_src, grand_product_dst)
}

#[allow(dead_code)]
pub fn print_sizes() {
    print_size::<LookupChallenges>("LookupChallenges");
    print_size::<RangeCheck16ArgsLayout>("RangeCheck16ArgsLayout");
    print_size::<DelegationChallenges>("DelegationChallenges");
    print_size::<DelegationRequestMetadata>("DelegationRequestMetadata");
    print_size::<DelegationProcessingMetadata>("DelegationProcessingMetadata");
    print_size::<MemoryChallenges>("MemoryChallenges");
    print_size::<FlattenedLookupExpressionsLayout>("FlattenedLookupExpressionsLayout");
    print_size::<FlattenedLookupExpressionsForShuffleRamLayout>(
        "FlattenedLookupExpressionsForShuffleRamLayout",
    );
    print_size::<LazyInitTeardownLayout>("LazyInitTeardownLayout");
    print_size::<ShuffleRamAccess>("ShuffleRamAccess");
    print_size::<ShuffleRamAccesses>("ShuffleRamAccesses");
    print_size::<RegisterAndIndirectAccesses>("RegisterAndIndirectAccesses");
}
